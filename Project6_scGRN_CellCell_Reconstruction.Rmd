---
title: "Project 6: scGRN and Cell-Cell Interaction Network Reconstruction"
output: html_document
---

```{r}
library(dplyr)
library(Seurat)
library(patchwork)
library(scmap)
library(minet)
library(SingleCellExperiment)
library(GENIE3)

setwd("/Users/michellechang/Downloads")
source("Project5_helper.R")
syn_data<-utils_loadObject("synthetic_expX_proj6.rda")
mmTFs<-utils_loadObject("synthetic_TFs_proj6.rda")
GRN<-utils_loadObject("synthetic_gs_proj6.rda")
sce_bertie<-utils_loadObject("bertie_e7.5_proj6.rda")
LR_pairs<-utils_loadObject("LR_pairs.rda")
```

```{r}
# Simulate a bulk expression matrix. Create 30 samples by randomly selecting without replacement 25 single cells and averaging their expression.

syn_seurat <- CreateSeuratObject(counts = syn_data, project = "synthetic", min.cells = 3, min.features = 200)
syn_seurat = NormalizeData(syn_seurat, normalization.method = "LogNormalize")
syn_expDat = as.matrix(syn_seurat[["RNA"]]@data)

dimensions = dim(syn_expDat)
pickCells<-function(sampTab, cell_num=25){
  rows = sample(1:dimensions[1], cell_num, replace=F)
  # This generates a vector of length sample_num*cell_num with no repeat numbers. That way, every 25 entries together make up a bulk sample, totaling to 30 samples made by random selection w/o replacement.
  selection = c()
  for (i in 1:length(rows)){
    stX<-sampTab[rows[i],]
    selection = rbind(selection, stX)
  }
  return(selection)
}

bulk_data = c()
sample_num = 30
cell_num = 25
for (i in 1:sample_num){
  bulk_vals = c()
  selection = pickCells(syn_expDat, cell_num)
  for (j in 1:dimensions[2]){
    cells_by_gene = selection[,j]
    avg = mean(cells_by_gene)
    bulk_vals = cbind(bulk_vals, avg)
  }
  bulk_data = rbind(bulk_data, bulk_vals)
}

colnames(bulk_data) <- colnames(syn_expDat)

```

```{r}
# Reconstruct the GRN using the synthetic single cell data provided. Reconstruct the GRN using the bulk data from the previous step.
mim_syn <- build.mim(syn_expDat,estimator="pearson") 
net_syn <- clr(mim_syn)

mim_bulk <- build.mim(bulk_data,estimator="pearson") 
net_bulk <- clr(mim_bulk)

# Note: I'm not sure if there is a way/function to visualize the reconstructed GRN for each? Because right now, it's just a bunch of numbers.
```

```{r}
# function to find precision and recall
findPR <- function(threshold, network, gold){
  # a lot of the data is 0s, so let us make a df that has the TF and TG and the correlation score if it is not 0
  nonzero <- data.frame(matrix(ncol = 3, nrow = 0))
  colnames(nonzero) <- c("TF", "TG", "Correlation")
  
  dfRN <- rownames(network)
  dfCN <- colnames(network)
  
  for(r in 1:nrow(network)){
    for(c in 1:ncol(network)){
      if(network[r,c] >= threshold*max(network)){ # currently using the top 5% bc this is taking forever to run
        nonzero <- rbind(nonzero, c(dfRN[r], dfCN[c], network[r,c]))
      }
    }
  }
  
  # since there isn't a total overlap between the gold standard relationships and the model check if there is overlap 
  TP <- 0
  FN <- 0
  FP <- 0
  
  for(i in 1:nrow(nonzero)){
    for(j in 1:nrow(GRN)){
      if(as.character(nonzero[i,1]) == as.character(GRN[j,1]) && as.character(nonzero[i,2]) == as.character(GRN[j,3])){# if true positive
        TP <- TP + 1
      }
      else if(as.character(nonzero[i,1]) == as.character(GRN[j,1]) && as.character(nonzero[i,2]) != as.character(GRN[j,3])){# if makes a pair where one gene is in gold standard and one isnt, FP
        FP <- FP + 1
      }
      else if(as.character(nonzero[i,1]) != as.character(GRN[j,1]) && as.character(nonzero[i,2]) == as.character(GRN[j,3])){# if makes a pair where one gene is in gold standard and one isnt, FP
        FP <- FP + 1
      }
      else{# if not TP or FP, group as FN
        FN <- FN + 1
      }
    }
  }
  
  # now we have  counts for each category, we can calculate the precision and recall
  recall = TP / (TP + FN)
  precision = TP / (TP + FP)
  
  #return both
  pr = c(precision, recall)
  # check = c(TP,FP,FN)
  return(pr)
  # return(check)
}


# function to find AUPR curve
AUPRcurve <- function(threshList, network, gold){
  p <- c()
  r <- c()
  for(thresh in threshList){
    temp <- findPR(thresh, network, gold)
    p <- c(p, temp[1])
    r <- c(r, temp[2])
    # print(temp)
  }
  plot(r, p,
       main = "Precision Recall Graph")
  # install.packages("MESS")
  require(MESS)
  AUPR_val = auc(r,p, type = 'spline')
  return(AUPR_val)
}

```

```{r}
# my R keeps crashing while trying to evaluate the entire network, so I am randomly sampling the dataframe that is a result of the clr method to have something

# function to get 100x100 df
smallNet <- function(df){
  dfRows <- df[sample(1:nrow(df), 500), ]
  dfFinal <- dfRows[ ,sample(1:ncol(df), 500)]
  return(dfFinal)
}

# smaller df for both networks
smallSyn <- smallNet(net_syn)
smallBulk <- smallNet(net_bulk)
```

```{r}
# AUPR for the synthetic and bulk (small version for now)
tl <- c(0.5,0.6,0.7,0.8,0.9)
AUPRcurve(tl, smallBulk, GRN)
AUPRcurve(tl, smallSyn, GRN)
```

```{r}
# Devise your own single-cell GRN reconstruction method. Use your method to reconstruct the GRN of the synthetic single cell data. Compare performance to existing method

library(GENIE3)
# set the parameters (# of cells and samples & threshold)
data = c()
sample_num = 30
cell_num = 1
threshold = 2 # pick 1~10

for (i in 1:sample_num){
  bulk_vals = c()
  selection = pickCells(syn_expDat, cell_num)
  for (j in 1:dimensions[2]){              
    cells_by_gene = selection[,j]
    avg = mean(cells_by_gene)
    bulk_vals = cbind(bulk_vals, avg)
  }
  data = rbind(data, bulk_vals)
}
colnames(data) <- colnames(syn_expDat)
syn_exprMatr <- t(data)

set.seed(123) # For reproducibility of results

# It might take more time to compute
#weightMat <- GENIE3(exprMatr)
# to decrease the computing times # to run this need to install the package "doRNG"
syn_weightMat <- GENIE3(syn_exprMatr, nCores=4, verbose=TRUE)

# normalize the value of threshold
Gen_th <- (((threshold - 1) * (max(syn_weightMat)-min(syn_weightMat))) / 9) + min(syn_weightMat)

#get link above the threshold
syn_linkList <- getLinkList(syn_weightMat)
syn_linkList<-syn_linkList[which(syn_linkList$weight>=Gen_th),]
syn_linka <- cbind.data.frame(regulatoryGene=syn_linkList$regulatoryGene , targetGene=syn_linkList$targetGene)

# Reconstruct grn using aracne
syn_mim_part2 <- build.mim(data,estimator="pearson") 
#net_part2 <- clr(mim_part2)
syn_aracneMat <- aracne(syn_mim_part2, eps=0)

# normalize the value of threshold
aracne_th <- (((threshold - 1) * (max(syn_aracneMat)-min(syn_aracneMat))) / 9) + min(syn_aracneMat)

syn_linkList2 <- getLinkList(syn_aracneMat)
syn_linkList2<-syn_linkList2[which(syn_linkList2$weight>=aracne_th),]
syn_linkb <- cbind.data.frame(regulatoryGene=syn_linkList2$regulatoryGene , targetGene=syn_linkList2$targetGene)

# UNION two links
syn_resultlink <- merge(syn_linka,syn_linkb, all=TRUE)

# assess our new method
gold <- cbind.data.frame(regulatoryGene = GRN$TF,targetGene=GRN$Target)
check <- merge(syn_resultlink,gold)


dimensions = dim(syn_resultlink)
dimensions_GENIE = dim(syn_linkList)
dimensions_ARACNE = dim(syn_linkList2)
weight_GENIE = rep(0,dimensions[1])
weight_ARACNE = rep(0,dimensions[1])
GRN_combo = matrix(unlist(syn_resultlink), ncol = 2)
GRN_GENIE = matrix(unlist(syn_linka), ncol = 2)
GRN_GENIE = cbind(GRN_GENIE, syn_linkList$weight)
GRN_ARACNE = matrix(unlist(syn_linkb), ncol = 2)
GRN_ARACNE = cbind(GRN_ARACNE,syn_linkList2$weight)
for (i in 1:dimensions[1]){
  for (j in 1:dimensions_GENIE[1]){
    if (GRN_combo[i,1] == GRN_GENIE[j,1] && GRN_combo[i,2] == GRN_GENIE[j,2]){
      options(digits = 10)
      weight_GENIE[i] = as.double(GRN_GENIE[j,3])
    }
  }
  for (j in 1:dimensions_ARACNE[1]){
    if (GRN_combo[i,1] == GRN_ARACNE[j,1] && GRN_combo[i,2] == GRN_ARACNE[j,2]){
      options(digits = 10)
      weight_ARACNE[i] = as.double(GRN_ARACNE[j,3])
    }
  }
}
weight = rowMeans(cbind(weight_GENIE, weight_ARACNE), na.rm=TRUE)
syn_resultlink2 = cbind(GRN_combo,weight)
colnames(syn_resultlink2) = c("regulatoryGene", "targetGene", "weight")
```

```{r}
# Reconstruct GRN of real (Bertie) data using two separate methods: CLR and your method.

library(GENIE3)
bertie <- sce_bertie@metadata[[1]]
data <- t(bertie)
bertie_exprMatr <- t(data)
set.seed(123) # For reproducibility of results

# performing CLR on bertie data
bertie_mim <- build.mim(data,estimator="spearman")
bertie_net <- clr(bertie_mim)
#get target-regulator links 
bertie_linkListCLR<- getLinkList(bertie_net)

# to decrease the computing times # to run this need to install the package "doRNG"
bertie_weightMat2 <- GENIE3(bertie_exprMatr, nCores=4, verbose=TRUE)

# normalize the value of threshold
Gen_th <- (((threshold - 1) * (max(bertie_weightMat2)-min(bertie_weightMat2))) / 9) + min(bertie_weightMat2)

#get link above the threshold
bertie_linkList <- getLinkList(bertie_weightMat2)
bertie_linkList<-bertie_linkList[which(bertie_linkList$weight>=Gen_th),]
bertie_linka <- cbind.data.frame(regulatoryGene=bertie_linkList$regulatoryGene, targetGene=bertie_linkList$targetGene)

# Reconstruct grn using aracne
bertie_mim_part2 <- build.mim(data,estimator="pearson")
#net_part2 <- clr(mim_part2)
bertie_aracneMat <- aracne(bertie_mim_part2, eps=0)

# normalize the value of threshold
aracne_th <- (((threshold - 1) * (max(bertie_aracneMat)-min(bertie_aracneMat))) / 9) + min(bertie_aracneMat)

bertie_linkList2 <- getLinkList(bertie_aracneMat)
bertie_linkList2<-bertie_linkList2[which(bertie_linkList2$weight>=aracne_th),]
bertie_linkb <- cbind.data.frame(regulatoryGene=bertie_linkList2$regulatoryGene, targetGene=bertie_linkList2$targetGene)

# intersect two links
bertie_resultlink <- merge(bertie_linka,bertie_linkb)

dimensions = dim(bertie_resultlink)
dimensions_GENIE = dim(bertie_linkList)
dimensions_ARACNE = dim(bertie_linkList2)
weight_GENIE = rep(0,dimensions[1])
weight_ARACNE = rep(0,dimensions[1])
GRN_combo = matrix(unlist(bertie_resultlink), ncol = 2)
GRN_GENIE = matrix(unlist(bertie_linka), ncol = 2)
GRN_GENIE = cbind(GRN_GENIE,bertie_linkList$weight)
GRN_ARACNE = matrix(unlist(bertie_linkb), ncol = 2)
GRN_ARACNE = cbind(GRN_ARACNE,bertie_linkList2$weight)
for (i in 1:dimensions[1]){
  for (j in 1:dimensions_GENIE[1]){
    if (GRN_combo[i,1] == GRN_GENIE[j,1] && GRN_combo[i,2] == GRN_GENIE[j,2]){
      options(digits = 10)
      weight_GENIE[i] = as.double(GRN_GENIE[j,3])
    }
  }
  for (j in 1:dimensions_ARACNE[1]){
    if (GRN_combo[i,1] == GRN_ARACNE[j,1] && GRN_combo[i,2] == GRN_ARACNE[j,2]){
      options(digits = 10)
      weight_ARACNE[i] = as.double(GRN_ARACNE[j,3])
    }
  }
}
weight = rowMeans(cbind(weight_GENIE, weight_ARACNE), na.rm=TRUE)
bertie_resultlink2 = cbind(GRN_combo,weight)
colnames(bertie_resultlink2) = c("regulatoryGene", "targetGene", "weight")
```

```{r}
# function to find precision and recall for our own GRN reconstruction method
findPR <- function(threshold, network, gold){
  networkNEW = c()
  for(r in 1:nrow(network)){
    if(as.double(network[r,3]) >= threshold*max(as.double(network[,3]))){ 
      networkNEW <- rbind(networkNEW, network[r,])
    }
  }

  # since there isn't a total overlap between the gold standard relationships and the model check if there is overlap 
  TP <- 0
  FN <- 0
  FP <- 0
  end = dim(gold)[2]
  
  for(i in 1:nrow(networkNEW)){
    for(j in 1:nrow(gold)){
      if(as.character(networkNEW[i,1]) == as.character(gold[j,1]) && as.character(networkNEW[i,2]) == as.character(gold[j,end])){# if true positive
        TP <- TP + 1
      }
      else if(as.character(networkNEW[i,1]) == as.character(gold[j,1]) && as.character(networkNEW[i,2]) != as.character(gold[j,end])){# if makes a pair where one gene is in gold standard and one isnt, FP
        FP <- FP + 1
      }
      else if(as.character(networkNEW[i,1]) != as.character(gold[j,1]) && as.character(networkNEW[i,2]) == as.character(gold[j,end])){# if makes a pair where one gene is in gold standard and one isnt, FP
        FP <- FP + 1
      }
      else{# if not TP or FP, group as FN
        FN <- FN + 1
      }
    }
  }
  
  # now we have  counts for each category, we can calculate the precision and recall
  recall = TP / (TP + FN)
  precision = TP / (TP + FP)
  #return both
  pr = c(precision, recall)
  return(pr)
}

# function to find AUPR curve
AUPRcurve <- function(threshList, network, gold){
  p <- c()
  r <- c()
  for(thresh in threshList){
    temp <- findPR(thresh, network, gold)
    p <- c(p, temp[1])
    r <- c(r, temp[2])
    # print(temp)
  }
  plot(r, p,
       main = "Precision Recall Graph")
  # install.packages("MESS")
  require(MESS)
  AUPR_val = auc(r,p, type = 'spline')
  return(AUPR_val)
}

# AUPR values for the synthetic and bertie (small version for now) using our own GRN reconstruction method
tl <- c(0.5,0.6,0.7,0.8,0.9)
syncombo_AUPR = AUPRcurve(tl, syn_resultlink2, GRN)
bertiecombo_AUPR = AUPRcurve(tl, bertie_resultlink2, GRN) # WHAT IS THE GOLD STANDARD FOR BERTIE????
```

```{r}
# Cluster and assign identity of bertie data via marker genes, or any of the automated methods we have covered in class. Feel free to convert to a Seurat object first.

setwd("/Users/michellechang/Downloads")
source("Project5_helper.R")
sce_bertie<-utils_loadObject("bertie_e7.5_proj6.rda")

# Part I: SCMAP training and assessment

# sub-sampling the reference bertie data
set.seed(10)
tot_index = 1:dim(sce_bertie)[2]
subset_index = sample(tot_index, 0.9*length(tot_index)) 
sce_data = sce_bertie[, subset_index]
metadata(sce_data) = list()

sce_data <- selectFeatures(sce_data, suppress_plot = FALSE)
table(rowData(sce_data)$scmap_features)
# plot of the dropout rate vs expression

# indexing reference data set and visualizing it as a heatmap
colData(sce_data)
sce_data <- indexCluster(sce_data, cluster_col = "celltype")
head(metadata(sce_data)$scmap_cluster_index)
heatmap(as.matrix(metadata(sce_data)$scmap_cluster_index))

# Part 2: Clustering and cell-typing of bertie data

seurat_bertie <- as.Seurat(sce_bertie, counts = "counts", data = "logcounts")
seurat_bertie = NormalizeData(seurat_bertie, normalization.method = "LogNormalize")
# identifying highly variable features
seurat_bertie <- FindVariableFeatures(seurat_bertie, selection.method = "vst", nfeatures = 2000)
# Identify the 10 most highly variable genes
top10 <- head(VariableFeatures(seurat_bertie), 10)

# scaling data in dataset
all.genes <- rownames(seurat_bertie)
seurat_bertie <- ScaleData(seurat_bertie, features = all.genes)

# performing linear dimensional reduction (PCA)
seurat_bertie <- RunPCA(seurat_bertie, features = VariableFeatures(object = seurat_bertie))
# Examine and visualize PCA results a few different ways
print(seurat_bertie[["pca"]], dims = 1:5, nfeatures = 5)
DimPlot(seurat_bertie, reduction = "pca")

# determining dimensionality of dataset using ElbowPlot
ElbowPlot(seurat_bertie, ndims = 50)

# clustering cells of spangler data (using Louvain algorithm as default)
# choose top 33 PCs as significant PCs
seurat_bertie <- FindNeighbors(seurat_bertie, dims = 1:40)
seurat_bertie <- FindClusters(seurat_bertie, resolution = 0.5)
# Look at cluster IDs of the first 5 cells
head(Idents(seurat_bertie), 5)

# running non-linear dimensional reduction and visualizing
seurat_bertie <- RunUMAP(seurat_bertie, dims = 1:40)
DimPlot(seurat_bertie, reduction = "umap", label = TRUE)

# finding differentially expressed features (cluster biomarkers) for all clusters
bertie.markers <- FindAllMarkers(seurat_bertie, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25)
top150markers = bertie.markers %>% group_by(cluster) %>% top_n(n = 150, wt = avg_log2FC)
# generating an expression heatmap for the top 5 markers for each cluster
top5 <- bertie.markers %>% group_by(cluster) %>% top_n(n = 5, wt = avg_log2FC)
DoHeatmap(seurat_bertie, features = top5$gene) + NoLegend()

# performing cell-typing on bertie data

# converting Seurat object to a SingleCellExperiment
sce_bertie <- as.SingleCellExperiment(seurat_bertie)
rowData(sce_bertie)$feature_symbol <- rownames(sce_bertie)
sce_bertie <- sce_bertie[!duplicated(rownames(sce_bertie)), ]

# generating Sankey diagram
scmapCluster_results <- scmapCluster(
  projection = sce_bertie, 
  index_list = list(query = metadata(sce_data)$scmap_cluster_index),
  threshold = 0.4
)
head(scmapCluster_results$scmap_cluster_labs)
head(scmapCluster_results$scmap_cluster_siml)
plot(
  getSankey(
    colData(sce_bertie)$seurat_clusters, 
    scmapCluster_results$scmap_cluster_labs[,'query'],
    plot_height = 400
  )
)

seurat_bertie@meta.data$pred_types = extractClassLabel(scmapCluster_results, sce_bertie)
DimPlot(seurat_bertie, reduction = "umap", group.by = 'pred_types')

```

```{r}
# Extract subnetworks. Perform enrichment analysis to support findings

# extracting subnetworks????
celltype1_index = which(sce_bertie$pred_types == 'Blood progenitors 1')
cells1 = seurat_bertie[,celltype1_index]

# gene enrichment analysis using enrichr method
library(enrichR)
expMerged1 = cbind(bertie_subnet1,bertie_subnet2, ...) #combined expression matrix of subnetworks?
dbs<-c("Mouse_Gene_Atlas")

#testing between subnetwork 1 and 2
upIn12 = findDiffGenes(expMerged1,cname1 = "Subnet1", cname2 = "Subnet2")
enr12<-enrichr(upIn12,dbs[1])
enr12[[1]][1:15,1:4]
#testing between subnetwork 1 and 3
upIn13 = findDiffGenes(expMerged1,cname1 = "Subnet1", cname2 = "Subnet3")
enr13<-enrichr(upIn13,dbs[1])
enr13[[1]][1:15,1:4]
#testing between subnetwork 2 and 3
upIn23 = findDiffGenes(expMerged1,cname1 = "Subnet2", cname2 = "Subnet3")
enr23<-enrichr(upIn23,dbs[1])
enr23[[1]][1:15,1:4]

```

```{r}
# devise a method to quantify cell fate potency as we have defined in class, and apply it to the Bertie data.

# list of stem cell markers
pluripotency_markers = c('Acvr2b', 'Alcam', 'Arid1b', 'Ars2', 'Ash2l', 'Axin2', 'Bmi1', 'Brix', 'Cbx1', 'Cbx5', 'Ccna1', 'Ccnd1', 'Ccnd2', 'Ccne1', 'Ccnf', 'Cd24', 'Cd44', 'Cd9', 'Cdh3', 'Cdk2', 'Cdk4', 'Cdk6', 'Cdkn1b', 'Cdyl', 'Chd1', 'Chd7', 'Cks1b', 'Cldn6', 'Cnot1', 'Cnot2', 'Cnot3', 'Cops2', 'Cops4', 'Cpsf3', 'Crabp1', 'Dazap1', 'Dnmt3b', 'Dppa2', 'Dppa3', 'Dppa4', 'Dppa5', 'Dpy30', 'E2f1', 'Eed', 'Ehmt2', 'Eif2b1', 'Eif2b2', 'Eif2b3', 'Eif2s2', 'Epcam', 'Eras', 'Esrrb', 'Ewsr1', 'Ezh1', 'Ezh2', 'Fbxo15', 'Fgf13', 'Fgf4', 'Flt3', 'Foxd3', 'Foxh1', 'Fry', 'Fut4', 'Fut9', 'Gabrb3', 'Gal', 'Gbx2', 'Gdf3', 'Gja1', 'Gli1', 'Gli2', 'Gli3', 'Glis1', 'Gnl3', 'Grb7', 'H2afz', 'Has2', 'Hcfc1', 'Herc5', 'Hesx1', 'Hira', 'Hmga1', 'Hspa4', 'Hspb1', 'Id1', 'Id2', 'Igf2bp1', 'Ing5', 'Itga6', 'Jarid2', 'Kat2a', 'Kat5', 'Kat6a', 'Kdm1a', 'Kdm3a', 'Kdm4a', 'Kdm4c', 'Kdm5b', 'Kit', 'Kitlg', 'Klf12', 'Klf2', 'Klf4', 'Klf5', 'L1td1', 'Lefty1', 'Lefty2', 'Lin28a', 'Lin28b', 'Ly6e', 'Mapk1', 'Max', 'Mcm2', 'Mcrs1', 'Med1', 'Med10', 'Med12', 'Med13', 'Med14', 'Med17', 'Med19', 'Med24', 'Med28', 'Metap2', 'Mga', 'Mll', 'Mll2', 'Mll3', 'Mll5', 'Msi1', 'Mt1a', 'Mt2a', 'Mtf2', 'Mthfd1', 'Mybl2', 'Myc', 'Mycn', 'Nacc1', 'Nanog', 'Nanos1', 'Ncam1', 'Ncoa2', 'Ncoa3', 'Nfrkb', 'Nodal', 'Npr1', 'Nr0b1', 'Nr6a1', 'Nts', 'Onecut2', 'Otx1', 'Otx2', 'Paf1', 'Pcgf6', 'Pcid2', 'Pcna', 'Phc1', 'Phc2', 'Phc3', 'Pim2', 'Podxl', 'Pou5f1', 'Ppp1r3d', 'Prdm14', 'Prdm16', 'Prdm5', 'Prmt6', 'Prom1', 'Ptprz1', 'Pum1', 'Pum2', 'Rad21', 'Rb1', 'Rbbp4', 'Rbbp5', 'Rbbp7', 'Rbbp9', 'Rbl2', 'Rbx1', 'Rest', 'Rif1', 'Ring1', 'Rnf2', 'Rtf1', 'Sall1', 'Sall4', 'Sema4a', 'Setdb1', 'Setdb2', 'Sf3a1', 'Sf3a3', 'Sfrp2', 'Sirt2', 'Skil', 'Smad1', 'Smad2', 'Smad3', 'Smarca4', 'Smarca5', 'Smarcd1', 'Smarcb1', 'Smarcc1', 'Smc1a', 'Smo', 'Sox2', 'Sox3', 'Sp1', 'Spp1', 'Stag1', 'Stat3', 'Sub1', 'Suv39h2', 'Suz12', 'Taf2', 'Taf7', 'Tcf3', 'Tcf7l1', 'Tcl1a', 'Tdgf1', 'Terf1', 'Tert', 'Tgif', 'Thap11', 'Thy1', 'Tle1', 'Tnfrsf8', 'Top2a', 'Trim16', 'Trim24', 'Trim28', 'Utf1', 'Wdr18', 'Wdr5', 'Wnt2b', 'Wnt8a', 'Xpo7', 'Yy1', 'Zfhx3', 'Zfp41', 'Zfp42', 'Zfx', 'Zic2', 'Zic3', 'Zic5', 'Znf143', 'Znf219', 'Znf281', 'Zscan10')

# from this code from earlier
# # finding differentially expressed features (cluster biomarkers) for all clusters
# bertie.markers <- FindAllMarkers(seurat_bertie, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25)
# top150markers = bertie.markers %>% group_by(cluster) %>% top_n(n = 150, wt = avg_log2FC)

markers = top150markers$gene
count = rep(0, 10)
for (i in 1:length(pluripotency_markers)){
  for (j in 1:length(markers)){
    if (markers[j] == pluripotency_markers[i]){
      cluster_num = floor(j/150)+1
      count[cluster_num] = count[cluster_num] + 1
    }
  }
}
# The count vector is number of pluripotency markers that are present in differentially expressed genes list for each cluster. It is a relative indicator of the potency of each cluster 0-9.

# trajectory inference on bertie data to support cell fate potency method results
library(slingshot)
library(RColorBrewer)
sce_bertie <- as.SingleCellExperiment(seurat_bertie)
bertie_lineages =  getLineages(reducedDims(sce_bertie)$PCA[, 1:3], colData(sce_bertie)[, "pred_types"], start.clus = 'Caudal epiblast')
bertie_lineages
bertie_curves <- getCurves(bertie_lineages)

rd = reducedDims(sce_bertie)$PCA[, c(1,2)]
cl = colData(sce_bertie)[, "seurat_clusters"]
plotclr = brewer.pal(9,'Set1')[cl]
plot(rd, col = plotclr, asp=1,  pch = 16)
lines(bertie_lineages, lwd = 3)
```

